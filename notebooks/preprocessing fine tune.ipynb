{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24acfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xamon/Documenti/yci107/yci107-eda/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb15f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../resources/dataset_train_comments_v1.2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56ca510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=\"Unnamed: 0\",axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6561d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163a540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supponendo che la colonna attuale si chiami \"category\" e vuoi rinominarla in \"labels\"\n",
    "df = df.rename(columns={\"category\": \"labels\"})\n",
    "\n",
    "# Se df[\"labels\"] contiene stringhe, prima mappale su numeri\n",
    "label2id = {label: i for i, label in enumerate(df[\"labels\"].unique())}\n",
    "df[\"labels\"] = df[\"labels\"].map(label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "217959c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Neutrale': 0,\n",
       " 'Positiva': 1,\n",
       " 'Negativo': 2,\n",
       " 'Discriminatorio': 3,\n",
       " 'Complottismo': 4,\n",
       " 'Allarmismo': 5,\n",
       " 'Disinformazione': 6,\n",
       " 'Estremismi ideologici': 7}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91340b8d",
   "metadata": {},
   "source": [
    "### Clean emoj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b0bf18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgyYF8bf6AXRrjhGdJ14AaABAg</td>\n",
       "      <td>Peggiori condivido le tre che hai messo in sbo...</td>\n",
       "      <td>0</td>\n",
       "      <td>Peggiori condivido le tre che hai messo in sbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugxywle64-SAKNjBKS94AaABAg</td>\n",
       "      <td>Rido troppo coi dissing al Pisa hahaha ormai è...</td>\n",
       "      <td>1</td>\n",
       "      <td>Rido troppo coi dissing al Pisa hahaha ormai è...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgyYuLWkoyFkl-uwfed4AaABAg</td>\n",
       "      <td>Man utd❤</td>\n",
       "      <td>1</td>\n",
       "      <td>Man utd:red_heart:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgzA-XvP_yXKGfI2hE14AaABAg</td>\n",
       "      <td>adesso voglio anche il video per le terze</td>\n",
       "      <td>0</td>\n",
       "      <td>adesso voglio anche il video per le terze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UgzWWZLdUVVxJCgHRLh4AaABAg</td>\n",
       "      <td>Ciao Vito. Voglio un tuo parere per la Partita...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ciao Vito. Voglio un tuo parere per la Partita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>2b9d6ed2-82e5-487b-a71e-7cbf4e8e9bda</td>\n",
       "      <td>I’m vax forever voi morirete</td>\n",
       "      <td>5</td>\n",
       "      <td>I’m vax forever voi morirete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>72057cf5-7c95-40ee-a026-c5c53b4f13b5</td>\n",
       "      <td>I’m no vax forever e voi Es morirete</td>\n",
       "      <td>5</td>\n",
       "      <td>I’m no vax forever e voi Es morirete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>69ea6aba-d5e3-4aa5-8d40-614576767c4e</td>\n",
       "      <td>I’m no vax forever e morirete voi</td>\n",
       "      <td>5</td>\n",
       "      <td>I’m no vax forever e morirete voi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>23ea4c72-b573-41b4-b53b-a2c29af1df68</td>\n",
       "      <td>I’m forever e voi morirete</td>\n",
       "      <td>5</td>\n",
       "      <td>I’m forever e voi morirete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>e83c12e3-57b9-46c5-9895-cbc2f19e4c94</td>\n",
       "      <td>ane’m no vax forever E voi morirete</td>\n",
       "      <td>5</td>\n",
       "      <td>ane’m no vax forever E voi morirete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1605 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 commentId  \\\n",
       "0               UgyYF8bf6AXRrjhGdJ14AaABAg   \n",
       "1               Ugxywle64-SAKNjBKS94AaABAg   \n",
       "2               UgyYuLWkoyFkl-uwfed4AaABAg   \n",
       "3               UgzA-XvP_yXKGfI2hE14AaABAg   \n",
       "4               UgzWWZLdUVVxJCgHRLh4AaABAg   \n",
       "...                                    ...   \n",
       "1616  2b9d6ed2-82e5-487b-a71e-7cbf4e8e9bda   \n",
       "1617  72057cf5-7c95-40ee-a026-c5c53b4f13b5   \n",
       "1618  69ea6aba-d5e3-4aa5-8d40-614576767c4e   \n",
       "1619  23ea4c72-b573-41b4-b53b-a2c29af1df68   \n",
       "1620  e83c12e3-57b9-46c5-9895-cbc2f19e4c94   \n",
       "\n",
       "                                                   text  labels  \\\n",
       "0     Peggiori condivido le tre che hai messo in sbo...       0   \n",
       "1     Rido troppo coi dissing al Pisa hahaha ormai è...       1   \n",
       "2                                              Man utd❤       1   \n",
       "3             adesso voglio anche il video per le terze       0   \n",
       "4     Ciao Vito. Voglio un tuo parere per la Partita...       0   \n",
       "...                                                 ...     ...   \n",
       "1616                       I’m vax forever voi morirete       5   \n",
       "1617               I’m no vax forever e voi Es morirete       5   \n",
       "1618                  I’m no vax forever e morirete voi       5   \n",
       "1619                         I’m forever e voi morirete       5   \n",
       "1620                ane’m no vax forever E voi morirete       5   \n",
       "\n",
       "                                             text_clean  \n",
       "0     Peggiori condivido le tre che hai messo in sbo...  \n",
       "1     Rido troppo coi dissing al Pisa hahaha ormai è...  \n",
       "2                                    Man utd:red_heart:  \n",
       "3             adesso voglio anche il video per le terze  \n",
       "4     Ciao Vito. Voglio un tuo parere per la Partita...  \n",
       "...                                                 ...  \n",
       "1616                       I’m vax forever voi morirete  \n",
       "1617               I’m no vax forever e voi Es morirete  \n",
       "1618                  I’m no vax forever e morirete voi  \n",
       "1619                         I’m forever e voi morirete  \n",
       "1620                ane’m no vax forever E voi morirete  \n",
       "\n",
       "[1605 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_clean\"] = df[\"text\"].apply(lambda x: emoji.demojize(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8224615",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c15362e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1605/1605 [00:00<00:00, 5142.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Trasformo il dataframe in Dataset Hugging Face\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Carico il tokenizer del modello scelto\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenizzazione\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text_clean\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Split train/test\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0aae379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['commentId', 'text', 'labels', 'text_clean', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1284\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['commentId', 'text', 'labels', 'text_clean', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 321\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fe2b1e",
   "metadata": {},
   "source": [
    "### Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc9c7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_59228/634491200.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='648' max='648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [648/648 04:43, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.898811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.607034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.348364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.099050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.997841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.907654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.285900</td>\n",
       "      <td>0.855616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.285900</td>\n",
       "      <td>0.843061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=648, training_loss=1.117331893355758, metrics={'train_runtime': 284.208, 'train_samples_per_second': 36.143, 'train_steps_per_second': 2.28, 'total_flos': 1360850716459008.0, 'train_loss': 1.117331893355758, 'epoch': 8.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=len(set(df[\"labels\"]))\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bfe8b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./yc107-comment-classifier/tokenizer_config.json',\n",
       " './yc107-comment-classifier/special_tokens_map.json',\n",
       " './yc107-comment-classifier/vocab.txt',\n",
       " './yc107-comment-classifier/added_tokens.json',\n",
       " './yc107-comment-classifier/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./yc107-comment-classifier\")\n",
    "tokenizer.save_pretrained(\"./yc107-comment-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c54425",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1355118443.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mhuggingface-cli login\u001b[39m\n                    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yci107-eda (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
